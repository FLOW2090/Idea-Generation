{"Name": "fourier_feature_encoding", "Title": "Gaussian Fourier Features for Low-Dimensional Diffusion Encoding", "Experiment": "Replace SinusoidalEmbedding class with Gaussian Fourier feature encoding that projects inputs via random frequency matrices. Modify MLPDenoiser to use this new encoding scheme. Compare training curves, final KL divergences, and qualitative sample quality against baseline across all datasets. Key implementation: create FourierFeatureEmbedding class with random weight initialization and sine/cosine projections.", "Interestingness": 8, "Feasibility": 9, "Novelty": 7, "novel": true}
{"Name": "energy_guided_sampling", "Title": "Post-Training Controllable Generation via Energy-Guided Diffusion", "Experiment": "Implement control during sampling by: 1) Define target energy functions (E(x)) per dataset (e.g. E(x)=y coordinate for vertical positioning), 2) During denoising (inference loop), compute \u2207xE(x) via autograd, 3) Adjust model predictions with guidance: noise_pred = noise_pred - \u03bb * \u2207xE(sample). Compare guided (\u03bb>0) vs baseline (\u03bb=0) using: % samples satisfying E(x)<threshold, KL divergence of guided region subsets, and visual alignment. Key changes limited to inference code - training remains identical.", "Interestingness": 9, "Feasibility": 9, "Novelty": 7, "novel": false}
{"Name": "cluster_conditional_diffusion", "Title": "Unsupervised Cluster-Conditioned Generation via Diffusion Model Pseudo-Labeling", "Experiment": "1) Precompute k-means clusters (k=2-4) for each dataset before training. 2) Modify MLPDenoiser: add ClusterEmbedding layer (one-hot cluster IDs \u2192 embeddings) concatenated to existing embeddings. 3) During training: sample cluster ID from precomputed labels with 10% dropout (null ID for unconditional). 4) Inference: generate samples conditioned on specific cluster IDs. Evaluation: a) Train SVM on original cluster labels \u2192 measure accuracy on generated samples b) Compare within-cluster KL divergences vs baseline c) Visualize conditionally generated samples. Implementation requires adding cluster labels to dataset objects and minor denoiser input modifications.", "Interestingness": 9, "Feasibility": 9, "Novelty": 8, "novel": true}
{"Name": "feature_attention_denoiser", "Title": "Interpretable Coordinate Interaction Modeling via Attention in Diffusion Denoisers", "Experiment": "Enhance denoiser with coordinate-specific attention: 1) Implement FeatureAttentionBlock using 1-head attention over x/y features (input shape [batch, 2]). 2) Insert one block after every two ResidualBlocks in MLPDenoiser.network. 3) Analyze learned attention weights during generation. Compare to baseline via: a) KL divergence metrics, b) Visualization of attention weights across timesteps (show x-y interaction patterns), c) Generation quality on high-curvature datasets (dino/moons). Implementation: a) Minimal code changes with attention operating directly on coordinate dimensions, b) No hidden_dim adjustments needed due to lightweight attention. Training loop and embeddings remain unchanged.", "Interestingness": 9, "Feasibility": 9, "Novelty": 8, "novel": true}
{"Name": "hierarchical_time_modulation", "Title": "Layerwise Temporal Conditioning via FiLM for Diffusion Denoisers", "Experiment": "1) Modify ResidualBlock: Add FiLM layer that takes time embeddings. Implementation: a) New FiLMLayer class that projects time_emb to scale/shift parameters. b) In ResidualBlock forward: apply FiLM after activation. 2) Update MLPDenoiser: Pass time embedding to each ResidualBlock. 3) Compare against baseline on: a) Training convergence speed, b) KL divergence across datasets, c) Visual sample quality (especially for high-curvature shapes). Key changes: ResidualBlock now processes time_emb via FiLM (code changes limited to ~20 lines). Evaluation uses existing metrics but focuses on layerwise time integration benefits.", "Interestingness": 9, "Feasibility": 9, "Novelty": 8, "novel": true}
{"Name": "ddim_acceleration", "Title": "Efficient Sampling Trajectories for 2D Diffusion via DDIM Analysis", "Experiment": "Implement DDIM scheduler supporting \u03b7-controlled stochasticity: 1) Subclass NoiseScheduler to create DDIMScheduler with step() using x0 prediction and \u03b7 (0=deterministic, 1=DDPM). 2) Test inference with [10,20,50] steps (linearly spaced timesteps) and \u03b7\u2208{0,0.5,1}. 3) Compare to baseline DDPM on: a) KL divergence, b) inference time, c) visual sample quality/trajectories. Training remains unchanged. Key steps: Compute \u03c3 based on \u03b7 and \u03b1 schedules, update sample via x_{t-1}=\u221a\u03b1_prev x0 + \u221a(1-\u03b1_prev-\u03c3\u00b2)\u03b5 + \u03b7\u03c3\u03f5. Visualize intermediate denoising paths for different (\u03b7,step) combinations.", "Interestingness": 9, "Feasibility": 9, "Novelty": 7, "novel": true}
{"Name": "learned_coordinate_interaction", "Title": "Learned Coordinate Interaction Embeddings for Enhanced Geometric Awareness in Diffusion Models", "Experiment": "1) Create CoordInteractionEmbedding class: Processes concatenated x,y coordinates through a small MLP (2\u219264\u2192embedding_dim) to generate interaction features. 2) Modify MLPDenoiser: Keep original sinusoidal embeddings for x1/x2, add new interaction embedding. 3) Concatenate all three embeddings (x1, x2, interaction) as network input. 4) Adjust first linear layer input_dim from 3*embedding_dim to 3*embedding_dim (no size change). Compare to baseline via: a) KL divergence (all datasets), b) Training convergence speed, c) Visual inspection of circular/moon patterns. Implementation: Add ~20 lines for interaction MLP, minimal denoiser modifications. Maintains original training loop.", "Interestingness": 9, "Feasibility": 10, "Novelty": 8, "novel": true}
{"Name": "geometric_constraint_projection", "Title": "Hard Geometric Constraint Enforcement via Diffusion Sampling Projection", "Experiment": "Implement projection-based control during inference: 1) Create ConstraintProjector class with methods for common shapes (circle, polygon, etc.). 2) Modify sampling loop: after each noise_scheduler.step(), apply projection to constrained region. 3) Test with 3 constraint types per dataset (e.g. circle radius R, y > 0.5, convex polygon). Evaluation: a) Compute % points satisfying constraints, b) Compare KL divergence between constrained samples and original data intersections, c) Visualize adherence. Implementation requires only inference code changes - no model retraining. Key challenge: Maintaining sample quality while projecting.", "Interestingness": 8, "Feasibility": 9, "Novelty": 7, "novel": false}
{"Name": "multi_scale_wavelet_embedding", "Title": "Fixed-Scale Wavelet Projections for Localized Feature Learning in Diffusion Models", "Experiment": "1) Replace SinusoidalEmbedding with WaveletEmbedding using Mexican Hat wavelet. 2) Precompute 3 fixed scales (0.5x, 1x, 2x base frequency). Allocate embedding_dim equally across scales. 3) For each input (x1, x2, t), compute and concatenate wavelet responses per scale. 4) Compare to baseline via: a) KL divergence, b) Visual quality of high-curvature regions, c) Training convergence. Implementation: Compute wavelet responses per scale using fixed formulae, split embedding dimensions, and concatenate. Denoiser input dimensions unchanged. Analysis focuses on multi-scale vs single-scale (sinusoidal) geometric capture.", "Interestingness": 9, "Feasibility": 10, "Novelty": 8, "novel": true}
{"Name": "adaptive_timestep_sampling", "Title": "Curriculum Learning via Loss-Adaptive Diffusion Training Timestep Sampling", "Experiment": "1) Initialize per-timestep loss tracker in NoiseScheduler with ones. 2) During training: a) Sample timesteps using probabilities p_t \u221d (tracked_loss[t]^0.5 + 1e-6) via torch.multinomial. b) After loss computation, update tracker: loss_ema[t] = 0.9*loss_ema[t] + 0.1*loss.detach().mean(). 3) Compare to baseline via: a) Training speed (steps to reach 90% min loss), b) Final KL divergences, c) Visualization of p_t evolution. Key changes: Add loss_ema tensor in NoiseScheduler.__init__, modify timestep sampling, add 2 lines for EMA updates. Retains original model architecture and evaluation pipeline.", "Interestingness": 9, "Feasibility": 10, "Novelty": 8, "novel": false}
{"Name": "anchor_positional_encoding", "Title": "Geometric Relational Embeddings via Trainable Spatial Anchors for Diffusion Denoisers", "Experiment": "1) Create AnchorEmbedding class: a) Initialize 3 trainable 2D anchor points. b) For input (x,y), compute L2 distances to anchors. c) Embed distances via SinusoidalEmbedding (dim=64). 2) Modify MLPDenoiser: a) Replace original input_mlp1/2 with CoordEmbedding (dim=64 each). b) Add AnchorEmbedding layer (dim=64). c) Concatenate [coord1, coord2, anchor, time] embeddings (total 64*4=256). 3) Train normally. Evaluate via: a) KL divergence, b) Anchor point trajectories (plot final positions vs data clusters), c) Sample quality on multi-modal datasets. Implementation: ~40 lines for new embeddings + denoiser input reconfiguration. Anchors provide explicit geometric priors without attention, requiring adjustment to first network layer input dimensions.", "Interestingness": 9, "Feasibility": 9, "Novelty": 8, "novel": true}
{"Name": "periodic_activation_denoiser", "Title": "Periodic Activation Functions for High-Fidelity Geometric Diffusion Modeling", "Experiment": "1) Modify ResidualBlock: Replace ReLU with torch.sin activation. 2) Implement SIREN-style initialization: Initialize each ResidualBlock's linear layer weights with uniform(-\u221a(6/fan_in), \u221a(6/fan_in)) where fan_in is input dimension, set biases to zero. 3) Train normally while monitoring gradient norms for stability. 4) Compare against baseline on: a) KL divergence (focus on 'dino'/'moons'), b) Training convergence curves, c) Visual sample geometric fidelity. Implementation requires only changes to ResidualBlock activation and weight initialization (~15 lines).", "Interestingness": 9, "Feasibility": 10, "Novelty": 8, "novel": true}
